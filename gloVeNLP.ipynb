{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luckyswaminathan/MusicVibe/blob/main/gloVeNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb2lO6knH3lx"
      },
      "outputs": [],
      "source": [
        "## imports\n",
        "## gloVe credits: \n",
        "## Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]\n",
        "## am adapting structure given by https://www.youtube.com/watch?v=e0WW5w13V64&t=68s&ab_channel=GregHogg to create \n",
        "## an NLP model for my app Music Vibe (data source requires no credits as is open source)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrTRqCb9IGnw",
        "outputId": "3769190b-890d-4c79-f857-26ba16784cd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1]    15299\n",
              "[1, 0, 0]    15057\n",
              "[0, 1, 0]     9644\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/luckyswaminathan/MusicVibe/main/tweet_emotions.csv'\n",
        "\n",
        "msc_df = pd.read_csv(url)\n",
        "\n",
        "\n",
        "sentiment_mapping = dict.fromkeys([\"anger\", \"hate\", \"sadness\", \"worry\"], (np.array([1,0,0])))\n",
        "\n",
        "sentiment_mapping.update(dict.fromkeys([\"boredom\", \"empty\", \"neutral\"], (np.array([0,1,0]))))\n",
        "\n",
        "sentiment_mapping.update(dict.fromkeys([\"enthusiasm\", \"fun\", \"happiness\", \"love\", \"relief\", \"surprise\"], (np.array([0,0,1]))))\n",
        "\n",
        "msc_df['sentiment'] = msc_df['sentiment'].map(sentiment_mapping)\n",
        "\n",
        "# Map the sentiment values using the mapping dictionary\n",
        "\n",
        "\n",
        "# Check the value counts\n",
        "msc_df['sentiment'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC319LOGEj2u",
        "outputId": "28f0cada-e151-477e-971d-17b109840a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-10 22:00:17--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip.1’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  5.07MB/s    in 4m 46s  \n",
            "\n",
            "2023-06-10 22:05:02 (5.08 MB/s) - ‘glove.twitter.27B.zip.1’ saved [1520408563/1520408563]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## using gloVE rather than word2vec because works better with small dataset\n",
        "\n",
        "!wget http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX9uc8B2UjpP",
        "outputId": "fc3b34a0-86ce-4f05-d14e-66a36a03bc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hpgpOLwFhAR",
        "outputId": "888c0e72-1142-4312-c413-ce5dabf77c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.twitter.27B.zip.1\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip glove.twitter.27B.zip.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq8mjp05FzWp",
        "outputId": "47367a4e-e018-4622-8b38-2114218db562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1193514"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "words = dict()\n",
        "def add_to_dict(d, filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      line = line.split(' ')\n",
        "      d[line[0]] = np.array(line[1:], dtype=float)\n",
        "\n",
        "add_to_dict(words, 'glove.twitter.27B.50d.txt')\n",
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93o47vgnKroC",
        "outputId": "dede9416-a719-4d95-b025-23894d3eb3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import nltk as nl\n",
        "nl.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xsyFBAslLOxV"
      },
      "outputs": [],
      "source": [
        "tokenizer = nl.RegexpTokenizer(r\"\\w+\")\n",
        "\n",
        "## LEMMATIZATION -- concatenating variants of a word to one form\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "## tokenizes and lemmatizes all words that are in gloVe word set\n",
        "def tokenLem(s):\n",
        "  tokens = tokenizer.tokenize(s)\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "  tokens = [word for word in tokens if word in words]\n",
        "\n",
        "  return tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CKoIPsRkQLa5"
      },
      "outputs": [],
      "source": [
        "def message_to_word_vectors(message, word_dict=words):\n",
        "  processed_list_of_tokens = tokenLem(message)\n",
        "\n",
        "  vectors = []\n",
        "\n",
        "  for token in processed_list_of_tokens:\n",
        "    if token not in word_dict:\n",
        "      continue\n",
        "    \n",
        "    token_vector = word_dict[token]\n",
        "    vectors.append(token_vector)\n",
        "  \n",
        "  return np.array(vectors, dtype=float)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf-YZUgDQ1P4",
        "outputId": "50c155a3-0e6f-4677-a43a-d16a3874e836"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000, 6000, 6000)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "## train_test_split\n",
        "\n",
        "\n",
        "\n",
        "train_df, mix_df = train_test_split(msc_df, random_state=42, test_size = 0.3)\n",
        "\n",
        "val_df, test_df = train_test_split(mix_df, random_state=42, test_size = 0.5)\n",
        "\n",
        "\n",
        "len(train_df), len(val_df), len(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ud1E0jtERyWa"
      },
      "outputs": [],
      "source": [
        "## splitting train,val, test into sentiment and content \n",
        "\n",
        "\n",
        "def df_to_SC(dff):\n",
        "  ## sentiment for sentence\n",
        "  y = dff['sentiment'].to_numpy()\n",
        "\n",
        "  ## content array\n",
        "  all_word_vector_sequences = []\n",
        "\n",
        "  for message in dff['content']:\n",
        "    message_as_vector_seq = message_to_word_vectors(message)\n",
        "    \n",
        "    if message_as_vector_seq.shape[0] == 0:\n",
        "      message_as_vector_seq = np.zeros(shape=(1, 50))\n",
        "\n",
        "    all_word_vector_sequences.append(message_as_vector_seq)\n",
        "  \n",
        "  return all_word_vector_sequences, y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "t6hmU-yqVYHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5bb7e6-769c-4200-eb32-c3a928566e5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "word_train, feel_train = df_to_SC(train_df)\n",
        "\n",
        "len(word_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_lengths = []\n",
        "\n",
        "for i in range(len(word_train)):\n",
        "  sequence_lengths.append(len(word_train[i]))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(sequence_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "crznmovIz67i",
        "outputId": "53caec3c-9c04-4001-9426-78ece804d1f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3180., 4294., 5883., 3589., 4014., 2663., 2932., 1152.,  282.,\n",
              "          11.]),\n",
              " array([ 1. ,  4.5,  8. , 11.5, 15. , 18.5, 22. , 25.5, 29. , 32.5, 36. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "auICpM1MUnM8"
      },
      "outputs": [],
      "source": [
        "## making the df into a np array\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "def pad_X(X, desired_sequence_length=38):\n",
        "  X_copy = deepcopy(X)\n",
        "\n",
        "  for i, x in enumerate(X):\n",
        "    x_seq_len = x.shape[0]\n",
        "    sequence_length_difference = desired_sequence_length - x_seq_len\n",
        "    \n",
        "    pad = np.zeros(shape=(sequence_length_difference, 50))\n",
        "\n",
        "    X_copy[i] = np.concatenate([x, pad])\n",
        "  \n",
        "  return np.array(X_copy).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IujKGkq0U4aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3955720-2dbf-42f7-a531-83d455a1c97b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n"
          ]
        }
      ],
      "source": [
        "word_train = pad_X(word_train)\n",
        "print(len(word_train[0]))\n",
        "\n",
        "\n",
        "word_val, feel_val = df_to_SC(val_df)\n",
        "word_val = pad_X(word_val)\n",
        "\n",
        "word_test, feel_test = df_to_SC(test_df)\n",
        "word_test = pad_X(word_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZVh_Q6BsY2or"
      },
      "outputs": [],
      "source": [
        "## LSTM model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Input(shape=(38, 50)))\n",
        "model.add(layers.LSTM(64, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.LSTM(64, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.LSTM(64, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(3, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "bnJGkyVqY7Gr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "cp = ModelCheckpoint('model/', save_best_only=True)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
        "              loss=CategoricalCrossentropy(), \n",
        "              metrics=['accuracy', AUC(name='auc')])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feel_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MryW-w16X5yY",
        "outputId": "c091e03b-250f-46d2-ed43-a3d9876572ef"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([1, 0, 0]) array([0, 1, 0]) array([0, 1, 0]) ... array([0, 0, 1])\n",
            " array([1, 0, 0]) array([0, 0, 1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpSzmVDPY_xJ",
        "outputId": "eff9bd0a-ca23-47a4-a61c-3a50ec85786c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 1]    10695\n",
            "[1, 0, 0]    10580\n",
            "[0, 1, 0]     6725\n",
            "Name: sentiment, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2.6180458158017763, 1: 2.6465028355387523, 2: 4.163568773234201}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "frequencies = pd.value_counts(train_df['sentiment']) \n",
        "print(frequencies)\n",
        "## weighting loss function as datset imbalanced\n",
        "\n",
        "weights = {0: frequencies.sum() / frequencies[0], 1: frequencies.sum() / frequencies[1], 2: frequencies.sum() / frequencies[2]}\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_train = word_train.astype(np.float32)\n",
        "word_val = word_val.astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert elements of feel_train to float32 type\n",
        "feel_train = np.array([np.array(arr, dtype=np.float32) for arr in feel_train])\n",
        "feel_val = np.array([np.array(arr, dtype=np.float32) for arr in feel_val])\n"
      ],
      "metadata": {
        "id": "4XZ8lC9z1KVn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A5sM7UvZD2y",
        "outputId": "1e2d1f71-d0cf-4a1e-a89e-eeb1e45d8764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 3.0454 - accuracy: 0.4793 - auc: 0.6787"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 121s 131ms/step - loss: 3.0454 - accuracy: 0.4793 - auc: 0.6787 - val_loss: 0.9900 - val_accuracy: 0.5237 - val_auc: 0.7064\n",
            "Epoch 2/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.8881 - accuracy: 0.5411 - auc: 0.7249"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 102s 117ms/step - loss: 2.8881 - accuracy: 0.5411 - auc: 0.7249 - val_loss: 0.9436 - val_accuracy: 0.5688 - val_auc: 0.7415\n",
            "Epoch 3/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.8495 - accuracy: 0.5520 - auc: 0.7353"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 101s 116ms/step - loss: 2.8495 - accuracy: 0.5520 - auc: 0.7353 - val_loss: 0.9336 - val_accuracy: 0.5693 - val_auc: 0.7442\n",
            "Epoch 4/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.8235 - accuracy: 0.5575 - auc: 0.7411"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 95s 109ms/step - loss: 2.8235 - accuracy: 0.5575 - auc: 0.7411 - val_loss: 0.9246 - val_accuracy: 0.5735 - val_auc: 0.7503\n",
            "Epoch 5/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.8055 - accuracy: 0.5646 - auc: 0.7456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 112s 128ms/step - loss: 2.8055 - accuracy: 0.5646 - auc: 0.7456 - val_loss: 0.9229 - val_accuracy: 0.5767 - val_auc: 0.7539\n",
            "Epoch 6/20\n",
            "875/875 [==============================] - 82s 93ms/step - loss: 2.7938 - accuracy: 0.5644 - auc: 0.7484 - val_loss: 0.9444 - val_accuracy: 0.5690 - val_auc: 0.7424\n",
            "Epoch 7/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.7795 - accuracy: 0.5673 - auc: 0.7515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 99s 113ms/step - loss: 2.7795 - accuracy: 0.5673 - auc: 0.7515 - val_loss: 0.9103 - val_accuracy: 0.5848 - val_auc: 0.7602\n",
            "Epoch 8/20\n",
            "875/875 [==============================] - 98s 112ms/step - loss: 2.7665 - accuracy: 0.5713 - auc: 0.7547 - val_loss: 0.9524 - val_accuracy: 0.5618 - val_auc: 0.7415\n",
            "Epoch 9/20\n",
            "875/875 [==============================] - 98s 112ms/step - loss: 2.7538 - accuracy: 0.5748 - auc: 0.7569 - val_loss: 0.9225 - val_accuracy: 0.5848 - val_auc: 0.7584\n",
            "Epoch 10/20\n",
            "875/875 [==============================] - 92s 106ms/step - loss: 2.7425 - accuracy: 0.5795 - auc: 0.7598 - val_loss: 0.9284 - val_accuracy: 0.5747 - val_auc: 0.7510\n",
            "Epoch 11/20\n",
            "875/875 [==============================] - 97s 111ms/step - loss: 2.7245 - accuracy: 0.5833 - auc: 0.7636 - val_loss: 0.9363 - val_accuracy: 0.5713 - val_auc: 0.7516\n",
            "Epoch 12/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.7173 - accuracy: 0.5822 - auc: 0.7651"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 112s 128ms/step - loss: 2.7173 - accuracy: 0.5822 - auc: 0.7651 - val_loss: 0.9048 - val_accuracy: 0.5923 - val_auc: 0.7651\n",
            "Epoch 13/20\n",
            "875/875 [==============================] - 82s 94ms/step - loss: 2.7001 - accuracy: 0.5890 - auc: 0.7688 - val_loss: 0.9338 - val_accuracy: 0.5687 - val_auc: 0.7514\n",
            "Epoch 14/20\n",
            "875/875 [==============================] - 75s 86ms/step - loss: 2.6963 - accuracy: 0.5914 - auc: 0.7695 - val_loss: 0.9166 - val_accuracy: 0.5777 - val_auc: 0.7577\n",
            "Epoch 15/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.6832 - accuracy: 0.5908 - auc: 0.7721"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 91s 104ms/step - loss: 2.6832 - accuracy: 0.5908 - auc: 0.7721 - val_loss: 0.9046 - val_accuracy: 0.5852 - val_auc: 0.7663\n",
            "Epoch 16/20\n",
            "875/875 [==============================] - 84s 96ms/step - loss: 2.6738 - accuracy: 0.5932 - auc: 0.7739 - val_loss: 0.9274 - val_accuracy: 0.5745 - val_auc: 0.7541\n",
            "Epoch 17/20\n",
            "875/875 [==============================] - ETA: 0s - loss: 2.6701 - accuracy: 0.5944 - auc: 0.7750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r875/875 [==============================] - 101s 115ms/step - loss: 2.6701 - accuracy: 0.5944 - auc: 0.7750 - val_loss: 0.8979 - val_accuracy: 0.5937 - val_auc: 0.7703\n",
            "Epoch 18/20\n",
            "875/875 [==============================] - 90s 103ms/step - loss: 2.6608 - accuracy: 0.5958 - auc: 0.7768 - val_loss: 0.9131 - val_accuracy: 0.5847 - val_auc: 0.7609\n",
            "Epoch 19/20\n",
            "875/875 [==============================] - 89s 102ms/step - loss: 2.6491 - accuracy: 0.5995 - auc: 0.7791 - val_loss: 0.9146 - val_accuracy: 0.5840 - val_auc: 0.7612\n",
            "Epoch 20/20\n",
            "875/875 [==============================] - 86s 99ms/step - loss: 2.6448 - accuracy: 0.6002 - auc: 0.7800 - val_loss: 0.9108 - val_accuracy: 0.5865 - val_auc: 0.7647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11bb8c17b0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "\n",
        "\n",
        "model.fit(tf.convert_to_tensor(word_train), tf.convert_to_tensor(feel_train), validation_data=(tf.convert_to_tensor(word_val), tf.convert_to_tensor(feel_val)), epochs=20, callbacks=[cp], class_weight=weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0GehHUM_aQt6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "best_model = load_model('model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "SA56tMzJaTOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94db665-3b11-4b71-d13f-5dbcf872c2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 6s 33ms/step\n",
            "[[0.12367542 0.25386485 0.6224598 ]\n",
            " [0.7277098  0.09531482 0.17697537]\n",
            " [0.24751244 0.06720192 0.6852857 ]\n",
            " ...\n",
            " [0.52078307 0.16503447 0.3141825 ]\n",
            " [0.1668983  0.17239393 0.6607078 ]\n",
            " [0.8534571  0.08443864 0.06210428]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_predictions = best_model.predict(word_test)\n",
        "print(test_predictions)\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print(classification_report(feel_test, test_predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1g6zVrKjX1MUqrJ6ptjk9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}